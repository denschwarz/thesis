% !TEX root = Master_Thesis.tex
\chapter{Analysis}
\label{ch:Ana}
	This chapter covers the analysis performed in this thesis. The general strategy and the goals of this analysis are given in section~\ref{sec:strategy}. A suitable jet clustering algorithm is studied and chosen on particle level in section~\ref{sec:jet_studies}. Here, also the selection on particle level is discussed. In section~\ref{sec:selection}, details of the selection on reconstruction level are presented. Furthermore, the final measurement phase space including a jet energy correction for XCone jets is discussed, resulting in a jet mass distribution which is then unfolded. The unfolding procedure is presented in section~\ref{sec:unfolding}.
	
\section{Analysis Strategy}
\label{sec:strategy}
	This analysis aims at highly boosted $t\bar{t}$ final states where all decay products from the fully hadronic top quark decay merge into a single jet. For this measurement the lepton + jets channel is used, where the event is tagged with the lepton, suppressing backgrounds. The measurement of the jet mass is then performed on the hadronically decaying top quark. The detailed selection is presented in section~\ref{sec:selection}. In the required phase space the distribution of the jet mass reconstructing a top quark decaying into quarks ($t\rightarrow b q \bar{q}'$) is measured. Afterwards an unfolding is performed by using the TUnfold \cite{tunfold} software package. The goal is to compare data unfolded to particle level with first principle calculations. Studies on particle level are presented in section~\ref{sec:jet_studies} to find a jet algorithm that fits this purpose.
	

\section{Jet Studies on Particle Level}
\label{sec:jet_studies}
	For this analysis, it is crucial to choose a suitable jet algorithm and cone size. The previously mentioned analysis at $8\;\text{TeV}$ \cite{torben_paper} uses Cambridge-Aachen jets with the radius parameter set to $R=1.2$ for its measurement. This large radius was chosen to compensate for low statistics in the boosted $t\bar{t}$ regime at $8\;\text{TeV}$. Since the cross section of $t\bar{t}$ production is much higher at a center-of-mass energy of $13\;\text{TeV}$ a smaller cone is expected to be applicable for this analysis. Additionally, jets clustered with Anti-$k_T$, HOTVR and XCone algorithms are studied and optimized in sections~\ref{sec:AK}, \ref{sec:HOTVR2} as well as \ref{sec:XCone_strat} and finally compared in section~\ref{sec:jet_comp} to find the algorithm most suitable for this analysis. The goal is to select a jet algorithm which returns jets in which all decay products of a hadronically decaying top quark are merged. In this case, the jet mass $M_\text{jet}$ is sensitive to the top quark mass $M_\text{top}$. The jet mass distribution should return a sharp peak at the top quark mass of around $173\;\text{GeV}$ to be able to extract the top quark mass. Jet studies are performed with a $t\bar{t}$ simulation using the information of MC simulations at particle level. The detailed selection is described in the following.

\subsection{Selection on Particle Level}
\label{sec:GenSel}
	All studies on particle level are performed with a simulated $t\bar{t}$ sample. Several selection criteria are used to select boosted top quark decays in the lepton + jets channel. Since the selection is applied on particle level, also particle level information is used. The selection reads:
	\begin{itemize}
	\item exactly one prompt electron or muon from the $W$ boson decay,
	\item veto on additional leptons,
	\item $p_T^{\text{1st jet}} > 400\;\text{GeV}$,
	\item $p_T^{\text{2nd jet}} > 200\;\text{GeV}$,
	\item Veto on additional jets with $p_T > 200\;\text{GeV}$,
	\item $\Delta R (\text{lepton, 2nd jet}) < \text{jet radius}$ and
	\item $M^{\text{1st jet}} > M^{\text{2nd jet + lepton}}$.
	\end{itemize}
	The first jet refers to the leading jet in $p_T$ of the respective jet clustering algorithm. It is expected to be originating from the hadronically decaying top quark, the second one is expected to contain the products of the leptonically decaying top quark. The purpose of the $p_T$ thresholds is to select boosted top decays. The veto on additional jets is set to select $t\bar{t}$ events where only one jet per top quark decay is found. Note, that the veto is not present for studies of the XCone algorithm since it will always return exactly two jets in this set up. A cut on the distance between lepton and second leading jet in $p_T$ enriches the sample in boosted topologies where the lepton is close to or inside the jet of the leptonically decaying top quark. This criterion is also obsolete for XCone, because of the selected clustering sequence (see section~\ref{sec:XCone_strat}). To suppress events where not all decay products of the hadronically decaying top quark end up in the jet with the highest transverse momentum, a mass criterion $M^{\text{1st jet}} > M^{\text{2nd jet + lepton}}$ is set. The criterion includes the assumption that the mass of the jet on the leptonic side is lower because the neutrino cannot be reconstructed. This selection is applied to every jet algorithm output to be able to compare these different approaches. All shown distributions are scaled to match a integrated luminosity of $37.76\;\text{fb}^{-1}$.

\FloatBarrier %draw figures of previous section before the new one starts	
\subsection{Studies with Anti-$k_T$}
\label{sec:AK}	
	Since the top quark decay should be reconstructed with one jet, all decay products need to end up inside the defined jet cone. Choosing different cone sizes has various effects. When the cone is small, not all decay products may end up in the jet and the jet mass is reconstructed smaller than the top mass. If the cone size is large, the probability to include additional radiation and pile-up grows and the resulting jet mass is reconstructed too high.	As a starting point Anti-$k_T$ jets with a radius of $0.8$ are selected since this is the CMS internal standard to reconstruct top quark jets. AK jets with a radius of $0.8$ and $1.2$ are presented in Fig.~\ref{fig:GEN_AK08} and \ref{fig:GEN_AK12}, respectively, to study the influence of the cone size. Additionally, a matching to generated particles is performed. If all three decay products of the top quark are clustered into the jet, the jet is called 'matched'. One can see that the distribution for AK8 jets features a shoulder of values smaller than the top quark mass. This is due to the higher fraction of 'not matched' events. In this case, these are events where not every decay product ends up in the jet. AK12 jets on the other hand often return a mass higher than the top quark mass which is due to underlying event. A larger cone size has a higher probability of including particles not originating from the top quark decay. Furthermore, even the peak position for AK12 jets is reconstructed above the top quark mass. It is also worth mentioning that with a larger cone size more events survive the selection criteria because a large jet sums up more particles and the jet thus acquires higher transverse momentum. Because of the better resolution in the peak region and a smaller tail, AK8 fits the purpose of this analysis well and is further used. To reduce additional energy clustered into the jet further, grooming algorithms like soft drop are used. A comparison of AK8 jets with and without soft drop is depicted in Fig.~\ref{fig:GEN_AK08sd}. With soft drop applied, the $W$ peak at $80\;\text{GeV}$ can be clearly identified. Additionally, jet masses above the top quark mass are suppressed. The distribution of AK8 jets with soft drop (Fig.~\ref{fig:GEN_AK08sd1}) will be compared to other clustering methods in section~\ref{sec:jet_comp}.

	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/AK08_matching}
		\caption{}
		\label{fig:GEN_AK08}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/AK12_matching}
		\caption{}
		\label{fig:GEN_AK12}
		\end{subfigure}
		\caption{Comparison of jet mass distributions of AK8 (a) and AK12 (b) jets. A smaller cone size (a) leads to a lower reconstructed mass while a large cone (b) returns higher masses. The fraction of 'matched' and 'not matched' events is shown in the histograms.}
	\end{figure}
	
	\begin{figure}[tb]
	    \centering
		\includegraphics [width=.5\textwidth]{../Plots/GenStudies/AK08softdrop_matching}
		\caption{Jet mass distribution of AK8 jets with soft drop. The influence of the grooming is especially visible between the $W$ boson mass and the top quark mass in comparison to Fig.~\ref{fig:GEN_AK08}.}
		\label{fig:GEN_AK08sd1}
	\end{figure}
	
\FloatBarrier %draw figures of previous section before the new one starts			
\subsection{Studies with HOTVR}
\label{sec:HOTVR2}
	Another approach to find an appropriate cone size is to use not a constant, but $p_T$ dependent radius parameter. Since decay products are Lorentz boosted with high momentum, the higher the $p_T$, the smaller cone size is necessary to contain all decay products. Thus, HOTVR (see section~\ref{sec:HOTVR}) directly addresses this. The default settings set the effective radius to $R_\text{eff} = \frac{600\;\text{GeV}}{p_T}$, which corresponds to a maximum radius of $1.5$ with the used selection of jets with $p_T > 400\;\text{GeV}$. The result is visible in Fig.~\ref{fig:GEN_HOTVR}. Due to the large cone size for the lowest possible jet momentum, the distribution shows a large tail. In comparison to the AK12 distribution, the peak is narrower while HOTVR does not feature a shoulder like AK8 does. The parameter to tune the HOTVR clustering is $\rho$. By lowering $\rho$, the effective radius shrinks. Figure~\ref{fig:GEN_HOTVRrho} shows a comparison of the jet mass for different $\rho$. The value of $\rho$ is decreased in $100\;\text{GeV}$ steps to a value of $300\;\text{GeV}$ which corresponds to a radius of $0.75$ for jets with a transverse momentum of $400\;\text{GeV}$. A behaviour similar to decreasing the radius of Anti-$k_T$ jets is visible. Increasing $\rho$ returns more events where all decay products end up in the jet cone, but a jet also includes more additional particles leading to a higher mass. Since the setting $\rho = 400\;\text{GeV}$ returns the highest fraction of events with a mass around the top quark mass, it will act as representative for HOTVR in the comparison presented in section~\ref{sec:jet_comp}.

	\begin{figure}[h]
		\centering
		\includegraphics [width=.6\textwidth]{../Plots/GenStudies/HOTVR_matching}
		\caption{Jet mass distribution of jets clustered with the HOTVR algorithm. Here, default values of the clustering procedure are used. The large tail can be explained with large jet radii for jets with a transverse momentum around $400\;\text{GeV}$.}
		\label{fig:GEN_HOTVR}
	\end{figure}	
	
	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/HOTVRrho600_matching}
		\caption{}
		\label{fig:GEN_HOTVR600}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/HOTVRrho500_matching}
		\caption{}
		\label{fig:GEN_HOTVR500}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/HOTVRrho400_matching}
		\caption{}
		\label{fig:GEN_HOTVR400}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/HOTVRrho300_matching}
		\caption{}
		\label{fig:GEN_HOTVR300}
		\end{subfigure}		
		\caption{Study of the influence of the HOTVR $\rho$ parameter on the jet mass. While $\rho$ is decreasing from (a) to (d) in $100\;\text{GeV}$ steps, the effective cone radius $R_\text{eff}$ decreases accordingly.}
		\label{fig:GEN_HOTVRrho}
	\end{figure}

\FloatBarrier %draw figures of previous section before the new one starts		
\subsection{Studies with XCone}
\label{sec:XCone_strat}
	The XCone jet algorithm described in section~\ref{sec:xcone} has already been tested resolving $t\bar{t}$ decays in studies for hadronically decaying top quark pairs, presented in a paper from Thaler and Wilkason \cite{xconetop}. In the called publication, the XCone algorithm is tuned to the $t\bar{t}$ final state, expecting six jets. Analogously to \cite{xconetop}, an approach to reconstruct the top quark decays with a strategy using two clustering steps is chosen in this analysis (see Fig.~\ref{fig:JetDisplay}). Firstly, XCone is required to find exactly two jets with a large radius ensuring that all decay products of the top quark end up in the jet. Thus, every particle from the top quark decay should be clustered into one of the jets. The goal of this first step is to separate the two top quarks into independent jets and suppress the influence of additional radiation. Now, the jets are identified if they contain the decay products of the hadronically decaying or leptonically decaying top quark via a distance measure to the lepton $\Delta R (\text{lepton, jet})$. To check if the categorization works, the distance $\Delta R$ between the hadronically decaying top quark on particle level and the selected jet is calculated. The distribution is shown in Fig.~\ref{fig:XCone_dR}. According to this plot, almost every jet is categorized correctly. A small fraction of events at $\Delta R = \pi$ indicates the events where the leptonically decaying top quark is reconstructed with the wrong jet. These events will be included into the unmatched fraction. The jet shape in the $\eta$-$\phi$-plane and all particles in the event are shown in Fig.~\ref{fig:JetDisplay1}. After that, the jets are further divided into smaller subjets. Since one expects only two visible components on the leptonic side, only two subjets are required, while the other jet contains three. This strategy will be referred to as '$2+5$' and is depicted in Fig.~\ref{fig:JetDisplay2}. The subjets are then combined to form a final jet that is used from now on.	
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.5\textwidth]{../Plots/GenStudies/XCone_dR_GEN_R20}
		\caption{Check of categorisation of XCone jets. The distance between generated hadronically decaying top quark and jet identified as containing its decay products is shown. The distribution is expected to peak at low values if the categorisation works, which is the case.}
		\label{fig:XCone_dR}
	\end{figure} 
	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/JetDisplayR15/xcone_incjets_event04}
		\caption{}
		\label{fig:JetDisplay1}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/JetDisplayR15/xcone_subjets_event04}
		\caption{}
		\label{fig:JetDisplay2}
		\end{subfigure}
		\caption{Display of the jet area from XCone jets clustered with the '$2+5$' approach after the first (a) and the second step (b) . The grey dots show particles identified by the PF algorithm, red circles indicate decay products from the hadronically decaying top quark where the bottom quark is additionally marked. Decay products from the leptonically decaying top quark are marked as follows: the black circle with star illustrates the bottom quark, the black circle with plus sign shows the lepton and the white circle marks the neutrino.}
		\label{fig:JetDisplay}
	\end{figure}
	Finally, the cone sizes have to be chosen. Here, $R_1$ denotes the radius parameter of the first clustering step, while $R_2$ measures the radii of the subjets. The subjets are set to a radius of $R_2=0.4$ to be comparable to the CMS standard for subjets, which are AK4 jets. Studies of the jet mass are made to determine the most suitable radius for the first clustering step. Figure~\ref{fig:JetDisplayR} shows an effect of larger cone sizes in the first clustering step. While the large smaller jet in Fig.~\ref{fig:JetDisplayR1} identifies the top quark decay products correctly, the large $R_1$ of jets in Fig.~\ref{fig:JetDisplayR2} include additional particles and misidentify them. Since all decay products of the top quark decay are yet included into the other two subjets, the jet mass will be reconstructed too high. On the other hand, a small cone may not include all decay products. This effect can also be seen in the jet mass distributions in Fig.~\ref{fig:XConeR1}. Based on these studies, the radius parameter is chosen to be $R=1.2$ because of less events in the shoulder around the $W$ mass and a smaller tail.\\
	To perform the clustering with data, an easier method is tested, where both fat jets contain three subjets, referred to as '$2+6$'. This approach is necessary because the lepton used to identify the leptonic jet is not fully defined at the stage where jet clustering is performed. The final jets are analogously categorized after a proper lepton identification into a jet originating from the hadronically and the leptonically decaying top quark. A comparison between the two methods (see Fig.~\ref{fig:GEN_XCone_comp}) shows that both return almost the same distribution. Thus, the '$2+6$' method is chosen to represent the XCone result.
	
	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/JetDisplayR10/xcone_subjets_event09}
		\caption{}
		\label{fig:JetDisplayR1}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/JetDisplayR20/xcone_subjets_event09}
		\caption{}
		\label{fig:JetDisplayR2}
		\end{subfigure}
		\caption{Jet area comparison between a small (a) and a large $R_1$ (b). The small cone only barely contains all decay products while the larger cone leads to misidentification of particles not belonging to the top quark decay.}
		\label{fig:JetDisplayR}
	\end{figure}	
		
	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
  		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone_GEN_R10}
		\caption{}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
  		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone_GEN_R12}
		\caption{}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
  		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone_GEN_R15}
		\caption{}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
  		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone_GEN_R20}
		\caption{}
		\end{subfigure}
						
		\caption{Jet mass distributions for different $R_1$. The smaller $R_1$ is, the more jets are reconstructed at the $W$ mass.}
		\label{fig:XConeR1}
	\end{figure}	
	
 	\begin{figure}[tb]
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone23_matching}
 		\label{fig:GEN_XCone23}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone33_matching}
 		\label{fig:GEN_XCone33}
 		\caption{}
 		\end{subfigure}
 		\caption{Comparison of the jet mass distribution of XCone jets clustered with the '$2+5$' (a) and the '$2+6$' (b) method. Both graphs show a very similar shape.}
 		\label{fig:GEN_XCone_comp}
 	\end{figure}
 	
\FloatBarrier %draw figures of previous section before the new one starts 	
\subsection{Comparing Jet Algorithms}
\label{sec:jet_comp}
	In this section, the resulting jet mass distributions of different jet clustering algorithms discussed above are compared. Figure~\ref{fig:Jet_Comp} shows all jet mass distributions examined above. All three clustering methods return a good resolution in the peak region while the maximum sits at the top quark mass. A more detailed look, how the jet algorithms distribute over different jet mass regions is presented in Tab. \ref{jet_numbers}. The Anti-$k_T$ algorithm with a cone radius of $R=0.8$ and soft drop applied reconstructs many events with a low mass, with the pronounced peak at the $W$ boson mass. This effect is explained by the small cone size. If only the decay products of the $W$ boson, but not the $b$ quark is clustered, a mass around the $W$ boson mass is expected. With a variable sized cone in HOTVR, this effect is reduced but more events with a mass larger than $200\;\text{GeV}$ are observed. XCone on the other hand combines the good aspects of Anti-$k_T$ and HOTVR. It returns a jet mass distribution with a narrow peak at the top quark mass and a low fraction of masses reconstructed too low or high. Note, that the performed matching is much more stringent for XCone jets. While the top quark decay products only have to be merged into the large jet for AK and HOTVR, a matching to the subjets is performed with XCone. However, XCone still returns a similar matched fraction than the AK and HOTVR jet algorithms.  Furthermore, much more jets are reconstructed correctly, therefore survive the selection criteria and lead to much higher event yield. This is explained by a softer selection of jets since an exclusive jet clustering algorithm will always return exactly two jets and a veto on additional jets is redundant. Because of the advantages of XCone, namely good resolution, peak position sensitive to the top quark mass and very high statistics, the measurement will be performed using XCone jets clustered with the '$2+6$' method.
	
 	\begin{figure}[tb]
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/GenStudies/AK08softdrop_matching}
 		\label{fig:Jet_Comp_ak}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/GenStudies/HOTVRrho400_matching}
 		\label{fig:Jet_Comp_HOTVR}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone33_matching}
 		\label{fig:Jet_Comp_XCone}
 		\caption{}
 		\end{subfigure} 		
 		\caption{Jet mass distributions of jets clustered with Anti-$k_T$ (a), HOTVR (b) and XCone (c). While all distributions show a good resolution in the peak region, AK shows a large fraction of masses reconstructed too low and XCone returns the largest statistics.}
 		\label{fig:Jet_Comp}
 	\end{figure}	
	
	\begin{table}
	\centering
	\begin{tabular}{l c c c }
	 & AK8 & HOTVR & XCone \\
	\hline
	\hline	 
	above $200\;\text{GeV}$ & $8.0\%$ & $23.6\%$ & $19.0\%$ \\ 
	below $150\;\text{GeV}$ & $31.0\%$ & $17.8\%$ & $17.7\%$ \\ 	
	$150\;\text{GeV} < M_\text{jet} < 200\;\text{GeV}$  & $61.0\%$ & $58.6\%$ & $63.3\%$ \\ 	
	not matched             & $36.3\%$ & $32.7\%$ & $35.5\%$ \\ 	
	\end{tabular}
	\caption{Overview of event yield fractions in different jet mass regions for the three compared jet clustering algorithms.}
	\label{jet_numbers}	
	\end{table}
	
\section{Studies on Reconstruction Level}
\label{sec:selection}
	Since the measurement should be performed with data, a similar jet mass distribution has to be achieved on reconstruction level. A selection is applied to simulation and data to obtain a data sample consisting of mostly $t\bar{t}$ events in the lepton+jets channel. The selection can be divided into two steps. Firstly, a baseline selection is used to suppress background processes, section~\ref{sec:PreSel}. Secondly, the final phase space is defined in section~\ref{sec:FinalSel} to select $t\bar{t}$ events with boosted top quarks. This is crucial for this analysis because the goal is to reconstruct the top quark with one jet. This can only be done if all of its decay products merge into one jet.

\subsection{Baseline Selection}
\label{sec:PreSel}
	In the lepton+jets channel of the $t\bar{t}$ process one expects to find exactly one muon or electron, two small jets from the hadronically decaying $W$ boson, two b-jets and missing transverse energy since the neutrino cannot be detected. This baseline selection is designed to remove non-$t\bar{t}$ events. Since this analysis focuses on the muon channel, the selection reads:
	\begin{itemize}
	\item single muon trigger (combination of "HLT\_Mu50\_v*" and "HLT\_TkMu50\_v*") with $p_T > 50\;\text{GeV}$ threshold,
	\item exactly one tight muon with $p_T > 55\;\text{GeV}$ and $|\eta| < 2.4$,
	\item veto on additional leptons,
	\item two-dimensional muon isolation criterion: \\ $\Delta R(\text{lepton, next AK4 jet}) > 0.4$ or $p_T^{\text{rel}}(\text{lepton, next AK4 jet}) > 40\;\text{GeV}$ \footnote{$p_T^{\text{rel}}(a,b) = \frac{|\vec{p_a} \times \vec{p_b}|}{|\vec{p_b}|}$},
	\item at least two AK4 jets with $p_T > 50\;\text{GeV}$ and $|\eta| < 2.4$,
	\item $\cancel{E}_T > 50\;\text{GeV}$ and
	\item at least one tight b-tag.
	\end{itemize}
	Because the dataset corresponding to the single muon trigger is used in this analysis, the trigger criteria have to be fulfilled in simulation as well. An additional cut on the muon $p_T$ above $53\;\text{GeV}$ is recommended \cite{MuonID} for this trigger to reach the plateau of trigger efficiency. Furthermore, a scale factor is applied to simulation to account for efficiency differences in data and simulation. Since only one lepton is expected in the lepton+jets channel of $t\bar{t}$, a veto on additional leptons is used to suppresses diboson events. Because no isolation criterium is applied for the muons, a two-dimensional cut is applied to reject QCD events. A window in the $\Delta R$-$p_T^{\text{rel}}$-plane is cut out where the majority of QCD that survive the lepton criteria accumulates. A display of the two-dimensional cut is presented in Fig.~\ref{fig:2D}. \\
	The requirements to find two AK4 jets with at least $50\;\text{GeV}$, missing transverse energy of at least $50\;\text{GeV}$ and a b-tag to preferably select $t\bar{t}$ events. For b-tagging a scale factor is applied to match efficiency in data and simulation. After applying the selection the remaining events contain about $80\%$ $t\bar{t}$, the main remaining backgrounds are $W+$jets and Single-Top production. 
 	\begin{figure}[tb]
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/TwoD_QCD}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/TwoD_TTbar}
 		\caption{}
 		\end{subfigure}
 		\caption{Distribution in the $\Delta R$-$p_T^{\text{rel}}$-plane for QCD (a) and $t\bar{t}$ events (b). Both distributions are normalised to unity. The window affected by the 2D cut is surrounded by red lines.}
 		\label{fig:2D}
 	\end{figure}
 	After applying the baseline selection, a difference in total number of events between simulation and data  as well as a $p_T$ dependent trend is visible (see Fig.~\ref{fig:PreSeljet}), probably coming from a mismodelled top quark $p_T$ distribution. The difference in $p_T$ spectra of the top quark has been observed in several publications, for example in a $t\bar{t}$ differential cross section measurement from CMS \cite{ttreweight}. An observed ratio between data and simulation in shown in Fig.~\ref{fig:topreweight}. To test this assumption a re-weighting of the top quark $p_T$ spectrum in $t\bar{t}$ simulation is applied according to Fig.~\ref{fig:topreweight}. The resulting histograms are presented in Fig.~\ref{fig:PreSel_reweight}. After this procedure, MC and data are well in agreement except for the AK4 jet $p_T$ in high energy regions. This is expected to not be well corrected by the re-weighting since it covers the range from $400\;\text{GeV}$ upwards with only one constant value. This effect is also visible in the measurement phase space discussed below and is one of the simulation properties that could be validated with this analysis.
 	 		
 	\begin{figure}[tb]
  		\centering
 		\includegraphics [width=.65\textwidth, trim=0 0 0 0, clip]{../Plots/../Plots/PreSel/08_bTag_jets/pt_jet_log.pdf}
 		\caption{Transverse momenta of all AK4 jets in the event. A trend in the ratio between data and simulation is observed.}
 		\label{fig:PreSeljet}
 	\end{figure}
 	
  	\begin{figure}[tb]
   		\centering
  		\includegraphics [width=.5\textwidth]{../Plots/top_reweight}
  		\caption{Ratio between data and simulation in differential top quark pair cross section in dependence on the transverse momentum of top quarks. Taken from \cite{topreweight}.}
  		\label{fig:topreweight}
  	\end{figure}	
 	
 	\begin{figure}[tb]
 		\centering
 		\begin{subfigure}{.45\textwidth}
  		\centering
		\includegraphics [width=\textwidth, trim=0 0 5.5cm 0, clip]{../Plots/PreSel_legend/ttbar_reweight_Muon/number_lin.pdf}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.45\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 5.5cm 0, clip]{../Plots/PreSel/ttbar_reweight_Muon/pt_1_log.pdf}
 		\caption{}
 		\end{subfigure} 		
 		\begin{subfigure}{.45\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 5.5cm 0, clip]{../Plots/PreSel_legend/ttbar_reweight_Jets/number_lin.pdf}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.45\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 5.5cm 0, clip]{../Plots/PreSel/ttbar_reweight_Jets/pt_jet_log.pdf}
 		\caption{}
 		\end{subfigure}
		\begin{subfigure}{.45\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 5.5cm 0, clip]{../Plots/PreSel_legend/ttbar_reweight_Event/BTAG_T_lin.pdf}
 		\caption{}
 		\end{subfigure} 	
  		\begin{subfigure}{.45\textwidth}
   		\centering
  		\includegraphics [width=\textwidth, trim=0 0 5.5cm 0, clip]{../Plots/PreSel/ttbar_reweight_Event/MET_log.pdf}
  		\caption{}
  		\end{subfigure}  	 			
 		\caption{Control distributions after applying a reweighting of the top quark $p_T$ in $t\bar{t}$ simulation. Displayed are number of muons (a), $p_T$ spectrum of muons (b), number of AK4 jets (c), $p_T$ distribution of all AK4 jets (d), number of b-tagged AK4 jets (e) and the spectrum of the missing transverse energy (f). }
 		\label{fig:PreSel_reweight}
 	\end{figure}	

\FloatBarrier %draw figures of previous section before the new one starts
\subsection{Measurement Phase Space}
\label{sec:FinalSel}
	The measurement phase space on reconstruction level is defined analogously to the particle level selection. Boosted topologies are selected by requiring the leading jet to surpass a cut on $p_T > 400\;\text{GeV}$. In addition, the mass of the leading jet is expected to be higher than the second jet mass if all top quark decay products are reconstructed correctly. Thus, on top of the baseline selection presented above, following criteria are checked:
	\begin{itemize}
	\item subjets $p_T > 30\;\text{GeV}$,
	\item $p_T^{\text{1st jet}} > 400\;\text{GeV}$ and
	\item $M^{\text{1st jet}} > M^{\text{2nd jet + lepton}}$.
	\end{itemize}
	In this phase space, the selection criteria refer to XCone jets clustered with the '$2+6$' method.	In addition to the definition on particle level, only subjets with a $p_T$ larger than $30\;\text{GeV}$ are considered to form the final jet. This requirement is set so suppress subjets which contain mostly objects from pile-up and not any decay product of the top quark. Figure~\ref{fig:MJet_raw1} shows the jet mass distribution after these jet requirements. Similar as on particle level, XCone returns a peak at the expected bin of the top quark mass. Thus, the reconstruction with XCone jets works very well. As seen after the baseline selection, simulation exceeds the number of events in data. In Fig.~\ref{fig:MJet_raw2}, $t\bar{t}$ simulation is scaled with a constant factor to match the total events in data and simulation. A good agreement between data and MC is visible. Of course, further procedures like unfolding will use the unscaled version as input. In addition, another variant of jet clustering with XCone is presented in Fig.~\ref{fig:MJet_raw3}. Here, the large XCone jet with radius $R=1.2$ is put into the soft drop algorithm. Albeit the grooming of soft drop, the '2+6' method returns a much sharper mass peak. While the turn on of the soft drop mass is comparable with '2+6', there are many jets with a mass reconstructed too high due to large contributions from pile-up.
 	\begin{figure}[tb]
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_raw/M_jet1__lin.pdf}
 		\caption{}
 		\label{fig:MJet_raw1}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
 		\centering
		\begin{tikzpicture}
		 \node[anchor=south west,inner sep=0] (image) at (0,0)
		 {\includegraphics[width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_raw_SF/M_jet1__lin.pdf}};
		 \node[align=left,font=\tiny] at (2.2, 4.2) {$t\bar{t}$ scaled};
		\end{tikzpicture} 
 		\caption{}
 		\label{fig:MJet_raw2}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
 		\centering
		\begin{tikzpicture}
		 \node[anchor=south west,inner sep=0] (image) at (0,0)
		 {\includegraphics[width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_raw_SF/SoftdropMass_had_lin.pdf}};
		 \node[align=left,font=\tiny] at (2.2, 4.2) {$t\bar{t}$ scaled};
		\end{tikzpicture} 
 		\caption{}
 		\label{fig:MJet_raw3}
 		\end{subfigure} 		
 		\caption{Jet mass distribution of XCone jets after applying the measurement phase space requirements. Additional to the raw output (a) a distribution where $t\bar{t}$ simulation is scaled to data is presented (b). Histogram (c) shows the soft drop mass of the large XCone jet ($R=1.2$) in comparison. It shows that a grooming via XCone subjet finding is much more effective than soft drop in this particular case.}
 		\label{fig:MJet_raw}
 	\end{figure}
	
\FloatBarrier %draw figures of previous section before the new one starts	
\subsection{Jet Energy Corrections for XCone Jets} 
	The normal procedure in CMS analyses is to apply jet energy corrections (see section~\ref{sec:jec}) to every jet collection used. Those jet energy corrections (JEC) have been derived by dedicated CMS groups and are dependent on the jet algorithm used to cluster jets. Since the XCone algorithm is not a standard jet finding procedure in CMS, there are no valid corrections available. Because the final jet measured in this analysis is a combination of subjets, only the subjets are corrected. A XCone jet with applied jet energy corrections refers then to a jet put together from corrected subjets. The first attempt to correct XCone jets is to use the AK4 jet corrections, since the jet shape should be very similar to XCone subjets with $R=0.4$ as they were used in this analysis. Figure~\ref{fig:MJet_jec} shows a comparison between jets with and without JEC applied. 
 	\begin{figure}[tb]
 		\begin{subfigure}{.5\textwidth}
 		\centering
		\begin{tikzpicture}
		 \node[anchor=south west,inner sep=0] (image) at (0,0)
		 {\includegraphics[width=\textwidth, trim=0.5cm 0 4cm 0, clip]{../Plots/PostSel/XCone_raw_SF/M_jet1__lin.pdf}};
		 \node[align=left,font=\tiny] at (2.2, 4.2) {$t\bar{t}$ scaled};
		\end{tikzpicture} 
 		\caption{}
 		\label{fig:MJet_jec1}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
 		\centering
		\begin{tikzpicture}
		 \node[anchor=south west,inner sep=0] (image) at (0,0)
		 {\includegraphics[width=\textwidth, trim=0.5cm 0 4cm 0, clip]{../Plots/PostSel/XCone_jec_SF/M_jet1__lin.pdf}};
		 \node[align=left,font=\tiny] at (2.2, 4.2) {$t\bar{t}$ scaled};
		\end{tikzpicture} 
 		\caption{}
 		\label{fig:MJet_jec2}
 		\end{subfigure}
 		\caption{Jet mass distribution of XCone jets before (a) and after applying AK4 jet energy corrections (b). A shift in jet masses to higher values is visible.}
 		\label{fig:MJet_jec}
 	\end{figure}	
 	An obvious shift in jet mass is visible, resulting in a peak position above the top quark mass. Fitting a Gaussian to the peak, one is able to obtain the peak position. With the peak at $172.2\;\text{GeV}$ with raw jets and a peak at $182.8\;\text{GeV}$ with corrected jets, the mass is reconstructed about $10\;\text{GeV}$ above the top quark mass when applying AK4 corrections. Since the data-simulation agreement is well in both cases and one can not optimize on the top quark mass in this analysis, different measures have to be defined to validate the jet energy correction. An attempt is made to test the subjets energy by a well known mass scale. Therefore, all three jet mass combinations $M_{ij}$ of two of the three subjets on the hadronic side are calculated. It is expected that the combination with the lowest jet mass should be proportional to the $W$ mass which is very precisely measured to $80.4\;\text{GeV}$ \cite{Wmass}. As shown in Fig.~\ref{fig:Wmass} the jet mass peak is reconstructed too high. Fitting with a Gaussian in the peak region returns values of $79.5\;\text{GeV}$ and $84.3\;\text{GeV}$ for raw and jets with AK4 correction, respectively. Since the raw subjets in Fig.~\ref{fig:Wmass1} show a agreement with the measured value of the $W$ boson mass, applying jet energy correction from AK4 jets to XCone subjets is not valid.
  	\begin{figure}[tb]
  		\begin{subfigure}{.5\textwidth}
  		\centering
 		\begin{tikzpicture}
 		 \node[anchor=south west,inner sep=0] (image) at (0,0)
 		 {\includegraphics[width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_raw_subjets_SF/min_mass_Wjet_zoom_lin.pdf}};
 		 \node[align=left,font=\tiny] at (2.2, 4.2) {$t\bar{t}$ scaled};
 		\end{tikzpicture} 
  		\caption{}
  		\label{fig:Wmass1}
  		\end{subfigure}
  		\begin{subfigure}{.5\textwidth}
  		\centering
 		\begin{tikzpicture}
 		 \node[anchor=south west,inner sep=0] (image) at (0,0)
 		 {\includegraphics[width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_jec_subjets_SF/min_mass_Wjet_zoom_lin.pdf}};
 		 \node[align=left,font=\tiny] at (2.2, 4.2) {$t\bar{t}$ scaled};
 		\end{tikzpicture} 
  		\caption{}
  		\label{fig:Wmass2}
  		\end{subfigure}
  		\caption{Lowest jet mass combination $\min(M_{ij})$ without (a) and with (b) JEC applied. The position of the peak is expected to match the $W$ boson mass of $80.4\;\text{GeV}$. The shift after applying JEC puts $\min(M_{ij})$ to higher values.} 
  		\label{fig:Wmass}
  	\end{figure}	
	In order to be able to correct XCone jets for response non linearities and pile-up effects, a correction factor on top of AK4 corrections is derived for XCone jets. For this, only events from $t\bar{t}$ simulation are used. Furthermore, only the subjets from the jet belonging to the hadronically decaying top quark are considered. A matching to generator jets is executed and the fraction $r=\frac{p_T^{\text{rec}}}{p_T^{\text{gen}}}$ calculated. This is done in different $p_T$ and $\eta$ regions. The mean $r$ in an $\eta$ region is then filled in a two dimensional histogram representing the $p_T$-$\eta$-plane (see Fig.~\ref{fig:Correction}). The bin boundaries are chosen to obtain enough statistics in each bin to suppress uncertainties (validated by the RMS\footnote{root mean square} width, see appendix Fig.~\ref{fig:A_rms}). 
		\begin{figure}[tb]
			\centering
			\includegraphics [width=.7\textwidth]{../Plots/Correction/Mean_numbers}
			\caption{Mean values of $r=\frac{p_T^{\text{rec}}}{p_T^{\text{gen}}}$ in the $p_T$-$\eta$ plane.}
			\label{fig:Correction}
		\end{figure}	
	The correction factor applied to every XCone jet is now $f = \frac{1}{r}$. In every $\eta$ bin a polynomial function is fitted to get a factor $f(p_T)$ to get a smooth transition between the different regions. An example of the fit is shown in Fig.~\ref{fig:Correction_fit} (all fit functions can be found in the appendix in Fig.~\ref{fig:A_fits}).
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.5\textwidth]{../Plots/Correction/Fits_example}
		\caption{Example of fit function. The correction factors are derived from Fig.~\ref{fig:Correction} and then fitted with a polynomial function of degree $2$.}
		\label{fig:Correction_fit}
	\end{figure}
	Now every subjet is corrected with a different $p_T$ dependent function according to its direction in $\eta$. Note that because of the loose ends of the fit, the correction factor is set constant for $p_T > 425\;\text{GeV}$. To verify this correction, the minimum jet mass from two subjets is again compared with the $W$ boson mass in Fig.~\ref{fig:Wmass_cor}. The peak position is again obtained with a Gaussian and is with its $80.6\;\text{GeV}$ in agreement with the $W$ boson mass of $M_W = 80.4\;\text{GeV}$.
  	\begin{figure}[tb]
  		\centering
 		\begin{tikzpicture}
 		 \node[anchor=south west,inner sep=0] (image) at (0,0)
 		 {\includegraphics[width=.7\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_cor_subjets_SF/min_mass_Wjet_zoom_lin.pdf}};
 		 \node[align=left,font=\small] at (3.3, 6.5) {$t\bar{t}$ scaled};
 		\end{tikzpicture} 
   		\caption{Lowest jet mass combination $\min(M_{ij})$ after AK4 jet energy correction and the correction for XCone. The peak position is in agreement with the value of the $W$ boson mass of $80.4\;\text{GeV}$.} 
  		\label{fig:Wmass_cor}
  	\end{figure}	  
  	Furthermore, the relative $p_T$ deviation between reconstruction level jets and particle level jets is calculated. A graph showing the mean and width (here calculated as RMS) of $\frac{p_T^\text{rec} - p_T^\text{gen}}{p_T^\text{gen}}$ in bins of $p_T^\text{rec}$ is presented in Fig.~\ref{fig:Reso}. While the width of the distribution (Fig.~\ref{fig:Reso2}) is not much influenced by the different jet energy correction stages, the mean shows a large improvement after the additional correction. The raw XCone jets and the ones corrected with AK4 corrections show a dependence on $p_T$ where the corrected jets are flat in this variable. Additionally, the corrected jets show a constant mean around zero which indicates a well performing correction. Figure~\ref{fig:Reso3} shows the mass resolution of the final jet. All but the first bin show a resolution below $10\%$, indicating a good reconstruction. The first bin shows a large value because of insufficient statistics for masses below $100\;\text{GeV}$. 
  	
  	\begin{figure}[tb]
  		\centering
  		\begin{subfigure}{.6\textwidth}
   		\centering
  		\includegraphics [width=\textwidth]{../Plots/Resolution_Subjets/pt_mean_rec_after}
  		\caption{}
  		\label{fig:Reso1}
  		\end{subfigure}
  		\begin{subfigure}{.6\textwidth}
   		\centering
  		\includegraphics [width=\textwidth]{../Plots/Resolution_Subjets/pt_rms_rec_after}
  		\caption{}
  		\label{fig:Reso2}
  		\end{subfigure}
  		\begin{subfigure}{.6\textwidth}
   		\centering
  		\includegraphics [width=\textwidth]{../Plots/Resolution_Mass/mass_rms_massbin.pdf}
 		\caption{}
 		\label{fig:Reso3}
 		\end{subfigure}
  		\caption{Mean (a) and width (b) of the relative deviation in jet $p_T$ between particle and reconstruction level. The mean stays almost constant after applying the customised correction. Furthermore, the width is rather independent on the correction. Figure (c) shows the width of the relative deviation in mass. Despite the first bin, the resolution lies below $0.1$.}
  		\label{fig:Reso}
  	\end{figure}
  	
  	
\FloatBarrier %draw figures of previous section before the new one starts	
\subsection{Final Jet Mass Distribution}
	After the events passed the baseline selection, the measurement phase space requirement and the newly derived jet energy correction, the final jet mass distribution is presented in Fig.~\ref{fig:MJet_final}. Data and Monte Carlo prediction agree very well after scaling $t\bar{t}$ simulation with a normalisation factor of $0.75$. The dependence on pile-up is studied in Fig.~\ref{fig:Mass_PU}. The orange band, consisting the majority of events, shows an almost flat distribution over the number of primary vertices per event. A slight trend, that high pile-up leads to higher masses is observed. However, this effect is not dominant since the red line, indicating a top quark mass of $173\;\text{GeV}$ is still in agreement with the region where jets accumulate. A jet mass distribution from the $8\;\text{TeV}$ analysis is shown in Fig.~\ref{fig:Torben_MJet} to compare both results. Cambridge/Aachen jets with a radius parameter of $1.2$ are used, selecting events with one jet with $p_T > 500\;\text{GeV}$. A drastic improvement in peak resolution and statistics is visible in the XCone distribution, promising higher statistics, a finer binning and less influence from pile-up when unfolding the data in the $13\;\text{TeV}$ analysis
	\begin{figure}[h]
  		\centering
 		\begin{tikzpicture}
 		 \node[anchor=south west,inner sep=0] (image) at (0,0)
 		 {\includegraphics[width=.8\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_cor_SF/M_jet1__lin.pdf}};
 		 \node[align=left,font=\small] at (3.5, 7.0) {$t\bar{t}$ scaled};
 		\end{tikzpicture} 
  		\caption{Jet mass distribution of the corrected jets clustered with XCone. This distribution will be used as input in the unfolding.} 
  		\label{fig:MJet_final}
  	\end{figure}
  		
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.8\textwidth]{../Plots/Mass_PileUp_2D.pdf}
		\caption{Dependence of the jet mass on the number of primary vertices in $t\bar{t}$ simulation. A slight trend is observed that higher pile-up generates higher jet masses. Every column is normalized to unity. The red line is drawn at the top quark mass of $173\;\text{GeV}$ as a reference.}
		\label{fig:Mass_PU}
	\end{figure}
	  	
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.6\textwidth]{../Plots/Torben/Torben_data_paper.pdf}
		\caption{Jet mass distribution from a similar analysis at $8\;\text{TeV}$. Besides the different dataset, Cambridge/Aachen jets with a radius parameter of $1.2$ are used. In this case, only jets with $p_T > 500\;\text{GeV}$ are shown. Taken from \cite{torben_paper}.}
		\label{fig:Torben_MJet}
	\end{figure}

	
\section{Unfolding}
\label{sec:unfolding}
	Most analyses at the LHC measure distributions in appropriate variables and then compare the obtained results in data with simulations. In this method the MC samples also include detector effects. What one measures in this case is the real distribution on particle level folded with a detector response simulated in detail for each event. Studying the difference in MC between particle level and reconstruction level, it is possible to calculate the probabilities that a measured value in a bin $y_i$ is originating from bin $x_i$ on particle level. A visualisation of this problem is drawn in Fig.~\ref{fig:Unfolding}.	
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.6\textwidth]{../Images/Unfolding.png}
		\caption{Schematic view of an unfolding procedure. The goal is to unfold a measured distribution $\mathbf{y}$ to obtain a true distribution $\mathbf{x}$ without detector effects. Taken from \cite{tunfold}.}
		\label{fig:Unfolding}
	\end{figure}
	The matrix $\mathbf{A}$ describing migrations from bins in $\mathbf{x}$ to bins in $\mathbf{y}$ can be calculated using simulations where both distributions $\mathbf{x}$ and $\mathbf{y}$ are known. Then, the inverted migration matrix can be used to obtain an estimate for data on particle level. The following equation denotes the basic problem one has to solve
	\begin{equation}
	\tilde{y}_i = \sum_{j=1}^{m} A_{ij}\tilde{x}_j, 1 \leq i \leq n,
	\label{eq:unfold}
	\end{equation}
	where $m$ and $n$ are the number of bins of the true and measured distributions, respectively. The tilde marks the statistical mean of $\mathbf{x}$ and $\mathbf{y}$. Here, one is interested in a distribution $x_j$ instead of $\tilde{x}_j$ making this problem non-trivial. If one only replaces $\tilde{y}_i \rightarrow y_i$ and $\tilde{x}_j \rightarrow x_j$, and solves for $x_j$ by inverting the matrix $\mathbf{A}$, statistical fluctuations of $\mathbf{y}$ would be amplified. Thus, fluctuations have to be damped with a regularisation.
	
\subsection{Regularised Unfolding with TUnfold}
	The TUnfold software package \cite{tunfold} provides a framework for regularised unfolding procedures in high energy physics. The Lagrangian implemented in TUnfold that is minimised is given by
	\begin{eqnarray}
	\label{eq:unfold_lagrange}
	\mathcal{L}(x,\lambda) &=& \mathcal{L}_1 + \mathcal{L}_2 + \mathcal{L}_3 
	\\ \nonumber \text{with}
	\\ 
	\label{eq:unfold_lagrange1}
	\mathcal{L}_1 &=& (\mathbf{y} - \mathbf{Ax})^\intercal \mathbf{V_{yy}}^{-1} (\mathbf{y} - \mathbf{Ax}),
	\\
	\label{eq:unfold_lagrange2}
	\mathcal{L}_2 &=& \tau^2 (\mathbf{x} - f_b \mathbf{x}_0)^\intercal (\mathbf{L}^\intercal \mathbf{L}) (\mathbf{x} - f_b \mathbf{x}_0),
	\\
	\label{eq:unfold_lagrange3}
	\mathcal{L}_3 &=& \lambda (Y-\mathbf{e}^\intercal \mathbf{x}) \ \text{with} \ Y=\sum_{i} y_i \ \text{and} \ e_j = \sum_{i}A_{ij}.
	\end{eqnarray}
	The first term $\mathcal{L}_1$ contains a standard least square minimisation where $\mathbf{V_{yy}}$ is the covariance matrix describing uncertainties. Secondly a regularisation with strength $\tau^2$ is used. A bias vector can be introduced using a factor $f_b$ and a vector $\mathbf{x}_0$ to suppress deviations of $\mathbf{x}$ from $f_b\mathbf{x}_0$. Additionally, three choices for the matrix $\mathbf{L}$ can be made to either regularise the absolute value, first or second derivative of $\mathbf{x}$. The final term $\mathcal{L}_3$ expresses an optional area constraint, checking differences in event counts between input and output. Since the free parameter $\tau$ defines the regularisation strength, a suitable value has to be found. This is achieved by an L-Curve scan, which finds the point of largest curvature in a graph. Two variables $L_x$ and $L_y$ are defined as follows:
	\begin{eqnarray}
	L_x  &=& \log \left(  \mathcal{L}_1 \right), \\
	L_y  &=& \log \left(  \frac{\mathcal{L}_2}{\tau^2} \right).
	\end{eqnarray}
	Now, a graph is constructed in the $L_x$-$L_y$-plane for many values of $\tau$. The point of largest curvature then indicates the point, where $\mathcal{L}_1$ and $\mathcal{L}_2$ equally influence the unfolding. The value of $\tau$ then corresponds to this point. 
	
\subsection{Migration Matrix}
\label{sec:migrations}
	To perform an unfolding, a migration matrix has to be filled. A matrix entry $A_{ij}$ contains the number of events that is generated in bin $i$ and reconstructed in bin $j$. Thus, a projection on one dimension returns either the jet mass distribution on particle or reconstruction level. Only events from the $t\bar{t}$ samples are considered to construct the matrix. If an event passes the particle level selection (see section~\ref{sec:GenSel}) and reconstruction level selection (see sections~\ref{sec:PreSel} and \ref{sec:FinalSel}) it is filled in the according bin. To account for events that pass only one selection, underflow bins are used, while jet masses above $400\;\text{GeV}$ are filled into overflow bins. Furthermore care has to be taken due to different weights because corrections like trigger and b-tagging scale factors as well as pile-up re-weighting are only applied on reconstruction level. Thus, the weight applied to an event is split into a generator level weight and a reconstruction level weight,
	\begin{equation}
	w_\text{event} = w_\text{gen} \cdot w_\text{reco}.
	\label{eq:weight}
	\end{equation}
	Since events without reconstruction level information only carry a generator weight, events are filled into underflow bins with a compensation weight to match the total number of events.
	\begin{equation}
	w_\text{comp} = w_\text{gen} \cdot (1 - w_\text{reco}).
	\label{eq:weight2}
	\end{equation}		
	Figure~\ref{fig:Migration} shows the migration matrix where every bin is scaled to the total event count in the whole column, not considering underflow bins. Thus, an entry $A_{ij}$ gives the probability that an event generated in bin $i$ is reconstructed in bin $j$. A clear diagonal is observed, showing the good performance of the mass reconstruction for XCone jets.
	
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.6\textwidth]{../Plots/Unfolding/Data/Migration_prob.pdf}
		\caption{Display of the migration matrix. Each bin is scaled to the total event count in a column.}
		\label{fig:Migration}
	\end{figure}
	
	
\subsection{Closure Tests}
	Various tests of the unfolding are performed in this analysis based on simulated events. Firstly, a MC sample is unfolded with itself. Since the L-curve scan does not work when using statistically dependent samples, a $\tau$ value is set manually. Nevertheless, the output distribution of TUnfold is expected to exactly match the particle level distribution. The comparison presented in Fig.~\ref{fig:Unfolding_same} shows an exact accordance and proves a correct filling of the migration matrix. Another approach to test the unfolding is to split the MC sample into two statistically independent parts. For this test, $10\%$ are randomly selected and saved as pseudo data, while the other $90\%$ are used to construct the migration matrix. The splitting is performed four times, with every pseudo dataset containing different events. The unfolded pseudo data is compared in Fig.~\ref{fig:Unfolding_split1234} to its distribution on particle level, referred to as truth. In all bins except the second and third, unfolded distribution and truth agree well. The disagreement in the second and third bin could indicate a bias in the unfolding. \\
	Therefore, a further test is performed to check the unfolding for model dependence. Again, the MC sample is split, but now the renormalisation and factorisation scales are varied in the pseudo dataset. Figure~\ref{fig:Unfolding_split_scale} shows the unfolded distribution of pseudo data with both scales varied up and down. Here, biases above (scaled up) and below (scaled down) the particle level distributions are visible, especially in the second and third bins. Thus, the current unfolding setup is biased by differently modelled inputs. This can be explained with the reconstruction selection efficiency. Since only about $15\%$ of events that passed the particle level selection also pass the reconstruction level selection, the unfolding is strongly influenced by the underflow bin of the migration matrix. As the $8\;\text{TeV}$ analysis showed  \cite{torben_paper}, this effect can be compensated by include migrations from lower $p_T$ thresholds into the matrix. For this analysis in the current status, a model uncertainty is calculated from the difference of the unfolded distribution and its truth in every bin. Here, the maximum difference of both scale variations is considered and then included in the unfolding of data.
	
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.55\textwidth]{../Plots/Unfolding/MC_Same/Unfold.pdf}
		\caption{Unfolding of a MC sample with itself. An exact agreement between unfolded distribution and its truth is observed, validating a correctly filled migration matrix.}
		\label{fig:Unfolding_same}
	\end{figure}	
	
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.55\textwidth]{../Plots/Unfolding/MC_Split_all/Unfold.pdf}
		\caption{A unfolding with a MC sample split into $10\%$ pseudo data and $90\%$ to fill the migration matrix is performed four times with different pseudo datasets. Statistical uncertainties in the truth level distribution are represented by the line thickness.}
		\label{fig:Unfolding_split1234}
	\end{figure}		
	
	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=\textwidth]{../Plots/Unfolding/MC_Split_up/Unfold.pdf}
		\caption{}
		\label{fig:Unfolding_split_up}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=\textwidth]{../Plots/Unfolding/MC_Split_down/Unfold.pdf}
		\caption{}
		\label{fig:Unfolding_split_down}
		\end{subfigure}		
		\caption{Unfolding with statistically independent MC samples where the renormalisation and factorisation scales in the pseudo data are scaled up (a) and down (b). The unfolded distributions are compared to the truth distributions where a bias is observed in both graphs.}
		\label{fig:Unfolding_split_scale}
	\end{figure}	
	
\FloatBarrier %draw figures of previous section before the new one starts	
\subsection{Unfolding of Data}
	Despite a preliminary migration matrix, a first test to unfold data is presented. Prior to the unfolding, background processes estimated from simulation are subtracted within the TUnfold software package. The unfolded distribution is depicted in comparison with the particle level distribution of the simulation in Fig.~\ref{fig:Unfolding_data}. Besides statistical uncertainties, indicated by the inner bars, the model uncertainty derived above is quadratically added to obtain a total uncertainty depicted by the outer error bars. Within the large uncertainties, the unfolded data agrees with the simulation. A more elaborate migration matrix is needed to damp these uncertainties which will be included in the future. The correlation matrix obtained from statistical uncertainties of the unfolded data is shown in Fig.~\ref{fig:Correlations}. Nearby bins are anti-correlated with correlation coefficients between $-0.6$ and $1$. The largest positive correlations observed in off-diagonal bins have values below $0.6$. This indicates an appropriate strength of the regularisation. The value for the regularisation strength $\tau$ is derived via a L-curve scan and was set to $\tau = 0.11$. Figure~\ref{fig:lcurve} shows the L-curve scan in the $L_x$-$L_y$ plane, where the point of largest curvature is highlighted.
	
	\begin{figure}[h]
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=\textwidth]{../Plots/Unfolding/Data/Unfold.pdf}
		\caption{}
		\label{fig:Unfolding_data}
		\end{subfigure}		
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=\textwidth]{../Plots/Unfolding/Data/Correlations.pdf}
		\caption{}
		\label{fig:Correlations}		
		\end{subfigure}	
		\caption{Unfolded data compared to the particle level distribution in simulation (a). The inner error bars show statistical uncertainties while the outer errors include the model uncertainties derived from scale variations. The correlation matrix, obtained from statistical uncertainties is displayed in (b).}
	\end{figure}
	\begin{figure}[h]
		\centering
		\includegraphics [width=.5\textwidth]{../Plots/Unfolding/Data/Lcurve.pdf}
		\caption{A display of the L-curve scan to derive the most suitable value for $\tau$. The point of largest curvature in the $L_x$-$L_y$ curve is highlighted by a red dot.}
		\label{fig:lcurve}
	\end{figure}	
	
\section{Summary of Results}
\label{sec:results}
	After a baseline selection to obtain a sample enriched by $t\bar{t}$ production, XCone jets are clustered to reconstruct top quark decays. The measurement phase space, selecting highly boosted top quarks is defined via two criteria:
	\begin{itemize}
	\item $p_T^{\text{1st jet}} > 400\;\text{GeV}$ and
	\item $M^{\text{1st jet}} > M^{\text{2nd jet + lepton}}$.
	\end{itemize}
	The fully hadronic top quark decay is reconstructed in a single jet. Figure~\ref{fig:Result1} shows the obtained jet mass distribution, which is sensitive to the top quark mass and resistant against pile-up while obtaining an excellent resolution and high statistics. \\
	Based on this distribution, an unfolding is performed, using simulation information to fill a migration matrix. The unfolding procedure is tested and validated with pseudo data and finally applied to data. Figure~\ref{fig:Result2} shows the unfolded distribution. Within the large uncertainties, unfolded data and the distribution on particle level from simulation show a good agreement. Further improvements are expected with a more elaborate phase space in the migration matrix and a closer look into the bins size of the measurement. This promises a measurement with much improved statistical and systematic uncertainties compared to the $8\;\text{TeV}$ result, and thus much higher sensitivity to the top quark mass.
	
	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=1.05\textwidth, trim=0 0 5cm 0, clip]{../Plots/PostSel/XCone_cor_SF/M_jet1__lin.pdf}
 		\caption{}
		\label{fig:Result1}		
		\end{subfigure}		
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=.95\textwidth,  trim=0 0.4cm 0 0, clip]{../Plots/Unfolding/Data/Unfold.pdf}
		\caption{}
		\label{fig:Result2}
		\end{subfigure}		
		\caption{As a result of this analysis, the unfolded data distribution (a) and the reconstructed jet mass (b) are shown. The very well performing XCone clustering algorithm reconstructs the top quark decay with high precision. Thus, the jet mass is sensitive to the top quark mass. The unfolded distribution agrees with the prediction by simulation but shows large model uncertainties.}
	\end{figure}
