\chapter{Analysis}
\label{ch:Ana}
	This chapter will cover the analysis performed for this thesis. A basic idea of the goals and strategy of this analysis is given in section \ref{sec:strategy}. Previous results, this analysis refers to, are presented in the following. Then a detailed look into event selections, studies on particle level, differences between jet algorithms and finally the unfolding process and its results follows in sections \ref{sec:jet_studies} to \ref{sec:results}.
\section{Analysis Strategy}
\label{sec:strategy}
	This analysis aims for boosted $t\bar{t}$ where all decay products from the top decays merge into a single jet. To measure in this phase space a selection of events is applied. The detailed selection is presented in section \ref{sec:selection}. In the required phase space the distribution of the jet mass of a top quark decaying into quarks ($t\rightarrow W^{+} b \rightarrow b q \bar{q}'$) is measured. Following a unfolding is performed using the TUnofld \cite{tunfold} software package. The goal is to compare data unfolded to particle level with first principle calculations. To fins a jet algorithm that fits this purpose, studies on particle level are presented in section \ref{sec:jet_studies}.
	

\section{Jet Studies on Particle Level}
\label{sec:jet_studies}
	For this analysis it is crucial to choose a suitable jet algorithm and cone size. The previous mentioned analysis \cite{torben_paper} uses Cambridge-Aachen jets with the radius parameter set to $R=1.2$ for its measurement. This large radius was chosen to compensate for low statistics in the boosted $t\bar{t}$ regime. Since the cross-section of $t\bar{t}$ production is much higher at a center-of-mass energy of $13\;\text{TeV}$ a smaller cone is expected to be applicable for this analysis. Additionally jets clustered with Anti-$k_T$, HOTVR and XCone algorithms are studied and optimized in sections \ref{sec:AKHOTVR} as well as \ref{sec:XCone_strat} and finally compared (section \ref{sec:jet_comp}) to find the algorithm most suitable for this analysis. The goal is to select a jet algorithm which returns jets in which all decay products of a hadronically decaying top quark are merged. In this case, the jet mass $M_\text{jet}$ is sensitive to the top quark mass $M_\text{top}$. To be able to extract the top quark mass, the jet mass distribution should return a sharp peak at the top quark mass of around $173\;\text{GeV}$. The jet studies are performed with a $t\bar{t}$ simulation using the information of MC simulations at particle level. The detailed selection is described in Section \ref{sec:GenSel}.

\subsection{Selection on Particle level}
\label{sec:GenSel}
	All studies on particle level are performed with a $t\bar{t}$ sample only. Several selection criteria are used to select boosted top quark decays in the lepton + jets channel. Since the selection is applied on particle level, also particle level information is used. The selection reads:
	\begin{itemize}
	\item direct selection of lepton + jets channel
	\item exactly one electron or muon
	\item veto on additional leptons
	\item $p_T^{\text{1st jet}} > 400\;\text{GeV}$ 
	\item $p_T^{\text{2nd jet}} > 200\;\text{GeV}$ 
	\item Veto on additional jets with $p_T > 200\;\text{GeV}$ 
	\item $\Delta R (\text{lepton, 2nd jet}) < \text{jet radius}$
	\item $M^{\text{1st jet}} > M^{\text{2nd jet + lepton}}$
	\end{itemize}
	Where the first jet refers to the leading jet in $p_T$ of the respective jet clustering algorithm. It is expected to be originating from the hadronically decaying top quark, the second one is expected contain the products of the leptonically decaying top quark. The purpose of the $p_T$ thresholds is to select boosted top decays. The Veto on additional jets is set to select $t\bar{t}$ events where one jet per top quark decay is expected. It is to mention, that the veto is not present in combination with XCone since it will always return exactly two jets in the used set up. A cut on the distance between lepton and second leading jet in $p_T$ prefers boosted topologies where the lepton is inside the jet of the leptonically decaying top quark. This criterion is also obsolete for XCone because of the selected clustering sequence (see section \ref{sec:XCone_strat}). To suppress events where not all decay products of the hadronically decaying top quark end up in the jet with the highest transverse momentum, a mass criterion $M^{\text{1st jet}} > M^{\text{2nd jet + lepton}}$ is set. The criterion includes the assumption that the mass of the jet on the leptonic side is lower because the neutrino cannot be reconstructed. This selection is applied to every jet algorithm output to be able to compare these different approaches. All shown distributions are scaled to match a integrated luminosity of $37.76\;\text{fb}^{-1}$.

\FloatBarrier %draw figures of previous section before the new one starts	
\subsection{Studies with Anti-$k_T$ and HOTVR}
\label{sec:AKHOTVR}	
	Since the top quark decay should be reconstructed with one jet, all decay products need to lay inside the defined jet cone. Choosing different cone sizes has various effects. When the cone is small, not all decay products may end up in the jet and the jet mass is reconstructed smaller than the top mass. If the cone size is large, the probability of additional radiation and pile-up grows and the resulting jet mass is reconstructed too high. 
	\subsubsection{Anti-$k_T$ Jets}
	As a starting point Anti-$k_T$ jets with a radius of $0.8$ are selected since this is the CMS intern standard to reconstruct top quark jets. To study the influence of the cone size, AK jets with a radius of $0.8$ and $1.2$ are presented in Fig. \ref{fig:GEN_AK08} and \ref{fig:GEN_AK12}, respectively. Additionally a matching is performed. If all three decay products of the top quark are clustered into the jet, the jet is called 'matched'. One can see that AK8 jets tend to deliver a jet mass lower than the top quark mass of about $173\;\text{GeV}$. This is due to the higher fraction of 'not matched' events. In this case, these are events where not every decay product ends up in the jet. AK12 jets on the other hand often return a mass higher than the top quark mass which is due to underlying event effects. A larger cone size has a higher probability of including particles not originating from the top quark one is interested in. Furthermore, even the peak position for AK12 jets is reconstructed above the top quark mass. It is also to mention that with a larger cone size more events survive the selection criteria because a large jet sums up more particles and thus more transverse momentum. Because of the better resolution in the peak region and much less tail, AK4 fits the purpose of this analysis well and is further used. To reduce additional energy clustered into the jet further, grooming algorithms like soft drop are used. A comparison of AK8 jets with and without soft drop is depicted in Fig. \ref{fig:GEN_AK08sd}. With soft drop applied, the $W$ peak can be clearly identified. Additionally, masses above the top quark mass are reduced. The distribution with AK8 jets and soft drop (Fig. \ref{fig:GEN_AK08sd1}) will be compared to other clustering methods in section \ref{sec:jet_comp}.

	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/AK08_matching}
		\caption{}
		\label{fig:GEN_AK08}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/AK12_matching}
		\caption{}
		\label{fig:GEN_AK12}
		\end{subfigure}
		\caption{Comparison of jet mass distributions of AK8 (a) and AK12 (b) jets. A smaller cone size (a) leads to a lower reconstructed mass while a large cone (b) returns higher masses. The fraction of 'matched' and 'not matched' events is shown in the histograms.}
	\end{figure}
	
	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/AK08softdrop_matching}
		\caption{}
		\label{fig:GEN_AK08sd1}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/AK08_matching}
		\caption{}
		\label{fig:GEN_AK08sd2}
		\end{subfigure}
		\caption{Comparison of jet mass distributions of AK8 with (a) and without (b) the soft drop algorithm applied. }
		\label{fig:GEN_AK08sd}
	\end{figure}
		
	\subsubsection{HOTVR Jets}
	Another approach to find a appropriate cone size is to used not a constant but $p_T$ dependent radius parameter. Since decay products are Lorentz boosted with high momentum, the higher the $p_T$, the smaller cone size is necessary to contain all decay products. Thus, HOTVR (see section \ref{sec:HOTVR}) directly addresses this property. The default settings set the effective radius to $R_\text{eff} = \frac{600\;\text{GeV}}{p_T}$, which corresponds to a maximum radius of $1.5$ with the used selection of jets with $p_T > 400\;\text{GeV}$. The result is visible in Fig. \ref{fig:GEN_HOTVR}. Due to the large cone size for the lowest possible jet momentum, the distribution is very similar to a AK jet with a large radius parameter. The parameter to tune the HOTVR clustering is $\rho$. By lowering $\rho$, the effective radius shrinks. Figure \ref{fig:GEN_HOTVRrho} shows a comparison of the jet mass for different $\rho$. It is decreased in $100\;\text{GeV}$ steps to a value of $300\;\text{GeV}$ which corresponds to a radius of $0.75$ for jets with a transverse momentum of $400\;\text{GeV}$. A behaviour similar to decreasing the radius of Anti-$k_T$ jets is visible. Increasing $\rho$ returns more events where all decay products end up in the jet cone, but a jet also includes more additional particles leading to a higher mass. Since the setting $\rho = 400\;\text{GeV}$ returns the highest fraction of events with a mass around the top quark mass, it will act as representative for HOTVR in the comparison presented in section \ref{sec:jet_comp}.

	\begin{figure}[tb]
		\centering
		\includegraphics [width=.5\textwidth]{../Plots/GenStudies/HOTVR_matching}
		\caption{Jet mass distribution of jets clustered with the HOTVR algorithm. Here, default values of the clustering procedure are used. The large tail can be explained with large jet radii for jets with a transverse momentum around $400\;\text{GeV}$.}
		\label{fig:GEN_HOTVR}
	\end{figure}	
	
	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/HOTVRrho600_matching}
		\caption{}
		\label{fig:GEN_HOTVR600}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/HOTVRrho500_matching}
		\caption{}
		\label{fig:GEN_HOTVR500}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/HOTVRrho400_matching}
		\caption{}
		\label{fig:GEN_HOTVR400}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/HOTVRrho300_matching}
		\caption{}
		\label{fig:GEN_HOTVR300}
		\end{subfigure}		
		\caption{Study of the influence of the HOTVR $\rho$ parameter on the jet mass. While $\rho$ is decreasing from (a) to (d) in $100\;\text{GeV}$ steps, the effective cone radius $R_\text{eff}$ increases accordingly.}
		\label{fig:GEN_HOTVRrho}
	\end{figure}

\FloatBarrier %draw figures of previous section before the new one starts		
\subsection{Studies with XCone}
\label{sec:XCone_strat}
	The XCone jet algorithm described in section \ref{sec:xcone} has already been tested resolving $t\bar{t}$ decays. Studies for hadronically decaying top quark pairs are presented in a paper from Thaler and Wilkason \cite{xconetop}. Here, the XCone algorithm is tuned to the $t\bar{t}$ final state, expecting six jets. Using the information that it is expected to find three jets from each top quark, a promising approach to reconstruct the top quark decays was made with a strategy using two clustering steps (see Fig. \ref{fig:JetDisplay}). Firstly, XCone is required to find exactly two jets with a large radius ensuring that all decay products of the top quark end up in the jet. Thus, every particle from the hard scattering should be clustered into one of the jets. The goal of this first step is to separate the two top quarks into independent jets.  Now, the jets are identified if they contain the decay products of the hadronically decaying or leptonically decaying top quark via a distance measure $\Delta R (\text{lepton, jet})$. To check if the categorization works, the distance $\Delta R$ between the hadronically decaying top quark on particle level and the selected jet is calculated. The distribution is shown in Fig. \ref{fig:XCone_dR}. According to this plot, almost every jet is categorized correctly. The jet shape in the $\eta$-$\phi$-plane, identification (orange indicates the jet identified as originating from the hadronically decaying top quark) and all particles in the event are shown in Fig. \ref{fig:JetDisplay1}. After that, the jets are further divided into smaller subjets. Since one expects only two visible components on the leptonic side, only two subjets are required, while the other jet contains three. This strategy will be referred to as '$2+5$' and is depicted in Fig. \ref{fig:JetDisplay2}. The subjets are then combined to form a final jet that is used from now on.	
	
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.5\textwidth]{../Plots/GenStudies/XCone_dR_GEN_R20}
		\caption{Check of categorisation of XCone jets. The distance between generated hadronically decaying top quark and jet identified as containing its decay products is shown. The distribution is expected to peak at low values if the categorisation works, which is the case.}
		\label{fig:XCone_dR}
	\end{figure} 
	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/JetDisplayR15/xcone_incjets_event04}
		\caption{}
		\label{fig:JetDisplay1}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/JetDisplayR15/xcone_subjets_event04}
		\caption{}
		\label{fig:JetDisplay2}
		\end{subfigure}
		\caption{Display of the jet area from XCone jets clustered with the '$2+5$' approach after the first (a) and the second step (b) . The grey dots show particles identified by the PF algorithm, red circles indicate decay products from the hadronically decaying top quark where the bottom quark is additionally marked. Decay products from the leptonically decaying top quark are marked as follows: the black circle with star illustrates the bottom quark, the black circle with plus sign shows the lepton and the white circle marks the neutrino.}
		\label{fig:JetDisplay}
	\end{figure}
	
	Finally, the cone sizes have to be chosen. The subjets are set to a radius of $R=0.4$ to be comparable to the CMS standard for subjets, which are AK4 jets. To determine the most suitable radius for the first clustering step, studies of the jet mass are made. A comparison of the jet area in Fig. \ref{fig:JetDisplayR} shows a higher expected misidentification rate for larger cones because of additional radiation or underlying event which leads to high masses especially when yet all decay products end up in the subjets. On the other hand, a small cone may not include all decay products. This effect can also be seen in the jet mass distributions in Fig. \ref{fig:XConeR1}. Based on these studies, the radius parameter is chosen to be $R=1.2$ because of less events in the shoulder around the $W$ mass and a smaller tail.

	%todo sagen, dass das gut funktioniert
	To perform the clustering with data, an easier method is tested, where both fat jets contain three subjets '$2+6$'. Afterwards the final jets are analogously categorized into a jet originating from the hadronically and the leptonically decaying top quark. A comparison between the two methods (see Fig \ref{fig:GEN_XCone_comp}) shows that both return almost the same distribution. Thus, the '$2+6$' method is chosen to represent the XCone result.
 	%todo show deltaR(lepton, fatjet) to show, that categorisation into had and lep works
	
	
	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/JetDisplayR10/xcone_subjets_event09}
		\caption{}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
	    \centering
		\includegraphics [width=\textwidth]{../Plots/JetDisplayR20/xcone_subjets_event09}
		\caption{}
		\end{subfigure}
		\caption{Jet area comparison between a small (a) and a large $R_1$ (b). The small cone only barely contains all decay products while the larger cone leads to misidentification of particles not belonging to the top quark decay.}
		\label{fig:JetDisplayR}
	\end{figure}	
		
	\begin{figure}[tb]
		\begin{subfigure}{.5\textwidth}
  		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone_GEN_R10}
		\caption{}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
  		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone_GEN_R12}
		\caption{}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
  		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone_GEN_R15}
		\caption{}
		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
  		\centering
		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone_GEN_R20}
		\caption{}
		\end{subfigure}
						
		\caption{Jet mass distributions for different $R_1$. The smaller $R_1$ is, the more jets are reconstructed at the $W$ mass. If $R_1$ increases, the probability of radiation ending up in the final jet grows and jets are more likely to have a mass above the top quark mass.}
		\label{fig:XConeR1}
	\end{figure}	
	
 	\begin{figure}[tb]
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone23_matching}
 		\label{fig:GEN_XCone23}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone33_matching}
 		\label{fig:GEN_XCone33}
 		\caption{}
 		\end{subfigure}
 		\caption{Comparison of the jet mass distribution of XCone jets clustered with the '$2+5$' (a) and the '$2+6$' (b) method.}
 		\label{fig:GEN_XCone_comp}
 	\end{figure}
 	
\FloatBarrier %draw figures of previous section before the new one starts 	
\subsection{Comparing Jet Algorithms}
\label{sec:jet_comp}
	In this section, the resulting jet mass distributions of different jet clustering algorithms discussed above are compared. Figure \ref{fig:Jet_Comp} shows all jet mass distributions examined above. All three clustering methods return a good resolution in the peak region while the maximum sits at the top quark mass. The Anti-$k_T$ algorithm with a cone radius of $R=0.8$ and soft drop applied reconstructs many events with a low mass, even showing a peak at the $W$ boson mass. This effect is explained by the small cone size. If only the decay products of the $W$ boson, but not the $b$ quark is clustered, a mass around the $W$ boson mass is expected. With a variable sized cone HOTVR this effect is reduced but more events with a mass larger than $200\;\text{GeV}$ are observed. XCone on the other hand combines the good aspects of Anti-$k_T$ and HOTVR. It return a jet mass distribution with a narrow peak at the top quark mass and a low fraction of masses reconstructed too low or high. Furthermore, much more jets are reconstructed correctly, therefore survive the selection criteria and lead to much higher event yield. This is also affected by a softer selection of jets since an exclusive jet clustering algorithm will always return exactly two jets and a veto on additional jets is redundant.
	
 	\begin{figure}[tb]
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/GenStudies/AK08softdrop_matching}
 		\label{fig:Jet_Comp_ak}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/GenStudies/HOTVRrho400_matching}
 		\label{fig:Jet_Comp_HOTVR}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/GenStudies/XCone33_matching}
 		\label{fig:Jet_Comp_XCone}
 		\caption{}
 		\end{subfigure} 		
 		\caption{Jet mass distributions of jets clustered with Anti-$k_T$ (a), HOTVR (b) and XCone (c). While all distributions show a good resolution in the peak region, AK shows a large fraction of masses reconstructed too low and XCone returns the largest statistics.}
 		\label{fig:Jet_Comp}
 	\end{figure}	
	
	%todo irriduceble background (deltaR (top, b))
	%todo vergleich auch mit XCone Softdrop!!! 		
	
\section{Studies on Reconstruction Level}
\label{sec:selection}
	To obtain a data set consisting of mostly $t\bar{t}$ events in the lepton+jets channel, a selection is applied to simulation and data. The selection can be divided into two steps. Firstly, a baseline selection is used to suppress background processes (see section \ref{sec:PreSel}). Secondly, the final phase space is defined (see section \ref{sec:FinalSel}) to select $t\bar{t}$ events with boosted top quarks. This is crucial for this analysis because the goal is to reconstruct the top quark with one jet. This can only be done if all of its decay products merge into one jet.

\subsection{Baseline Selection}
\label{sec:PreSel}
	In the lepton+jets channel of the $t\bar{t}$ process one expects to find exactly one muon or electron, two small jets from the hadronically decaying $W$ boson, two b-jets and missing transverse energy since the neutrino cannot be detected. This baseline selection is designed to remove non-$t\bar{t}$ events. Since this analysis focuses on the muon channel, the selection are:
	\begin{itemize}
	\item single muon trigger (combination of "HLT\_Mu50\_v*" and "HLT\_TkMu50\_v*") with $p_T > 50\;\text{GeV}$ threshold
	\item exactly one tight muon with $p_T > 55\;\text{GeV}$ and $|\eta| < 2.4$
	\item veto on additional leptons
	\item 2D Cut: $\Delta R(\text{lepton, next AK4 jet}) > 0.4$ or $p_T^{\text{rel}}(\text{lepton, next AK4 jet}) > 40\;\text{GeV}$ \footnote{$p_T^{\text{rel}}(a,b) = \frac{|\vec{p_a} \times \vec{p_b}|}{|\vec{p_b}|}$}
	\item at least two AK4 jets with $p_T > 50\;\text{GeV}$ and $|\eta| < 2.4$
	\item $\cancel{E}_T > 50\;\text{GeV}$
	%\item $S_T^\text{lep} > 100\;\text{GeV}$
	\item at least one tight b-tag

	\end{itemize}
	Because the data set corresponding to the called single muon trigger is used in this analysis, the trigger criteria have to be fulfilled in simulation as well. An additional cut on the muon $p_T$ at $55\;\text{GeV}$ is recommended for this trigger to reach the plateau of trigger efficiency. Furthermore, a scale factor is applied to simulation to account for efficiency differences in data and simulation. Since only one lepton is expected in the lepton+jets channel of $t\bar{t}$, a veto on additional leptons is used to suppresses diboson events. To reject QCD events, a two-dimensional cut is applied. A window in the $\Delta R$-$p_T^{\text{rel}}$-plane is cut out where the majority of QCD that survive the lepton criteria accumulates. A display of the 2D cut is presented in Fig. \ref{fig:2D}. The requirements to find two AK4 jets with at least $50\;\text{GeV}$, missing transverse energy of at least $50\;\text{GeV}$ and a b-tag prefer $t\bar{t}$ events because of the similar signature. For b-tagging a scale factor is applied to match efficiency in data and simulation. After applying the selection the remaining events contain about $80\%$ $t\bar{t}$, the main remaining backgrounds are $W+$jets and Single-Top production. 
	
	%todo ref muon pt cut recommendation
	%todo ref Muon Trigger SF
	%todo Lumi Plot

 	\begin{figure}[tb]
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/TwoD_QCD}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth]{../Plots/TwoD_TTbar}
 		\caption{}
 		\end{subfigure}
 		\caption{Distribution in the $\Delta R$-$p_T^{\text{rel}}$-plane for QCD (a) and $t\bar{t}$ events (b). The window affected by the 2D cut is surrounded by red lines. While QCD events mostly accumulate in the low left corner, many $t\bar{t}$ events will survive this cut.}
 		\label{fig:2D}
 	\end{figure}

 	\begin{figure}[tb]
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PreSel/08_bTag_Muon/number_lin.pdf}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PreSel/08_bTag_Muon/pt_1_log.pdf}
 		\caption{}
 		\end{subfigure} 		
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PreSel/08_bTag_jets/number_lin.pdf}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PreSel/08_bTag_jets/pt_jet_log.pdf}
 		\caption{}
 		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PreSel/08_bTag_Event/BTAG_T_lin.pdf}
 		\caption{}
 		\end{subfigure} 	
  		\begin{subfigure}{.5\textwidth}
   		\centering
  		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PreSel/08_bTag_Event/MET_log.pdf}
  		\caption{}
  		\end{subfigure}  	 			
 		\caption{Control distributions after applying the baseline selection. Displayed are number of muons (a), $p_T$ spectrum of muons(b), number of AK4 jets (c), $p_T$ distribution of all AK4 jets (d), number of b-tagged AK4 jets (e) and the spectrum of the missing transverse energy (f). In all histograms simulation exceeds the number of events in data. Furthermore a trend in the $p_T$ and $\cancel{E}_T$ spectra is visible.}
 		\label{fig:PreSel}
 	\end{figure}
 	
 	A difference in total number of events between simulation and data  as well as a $p_T$ dependent trend is visible, probably coming from a mismodelled top quark $p_T$ distribution. The difference in $p_T$ spectra of the top quark has been observed in several publications, for example in a $t\bar{t}$ differential cross section measurement from CMS \cite{ttreweight}. To justify this assumption a reweighting of the top quark $p_T$ spectrum in $t\bar{t}$ simulation is applied. The resulting histograms are presented in Fig. \ref{fig:PreSel_reweight}. In high energy regions simulation still exceeds data. After this procedure, MC and data are well in agreement. Hence, data is well understood at this point and the measurement phase space can be defined on top of the presented baseline selection.
	%todo reweight in Appendix??
 	\begin{figure}[tb]
 		\begin{subfigure}{.5\textwidth}
  		\centering
		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PreSel/ttbar_reweight_Muon/number_lin.pdf}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PreSel/ttbar_reweight_Muon/pt_1_log.pdf}
 		\caption{}
 		\end{subfigure} 		
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PreSel/ttbar_reweight_Jets/number_lin.pdf}
 		\caption{}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PreSel/ttbar_reweight_Jets/pt_jet_log.pdf}
 		\caption{}
 		\end{subfigure}
		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PreSel/ttbar_reweight_Event/BTAG_T_lin.pdf}
 		\caption{}
 		\end{subfigure} 	
  		\begin{subfigure}{.5\textwidth}
   		\centering
  		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PreSel/ttbar_reweight_Event/MET_log.pdf}
  		\caption{}
  		\end{subfigure}  	 			
 		\caption{Control distributions after applying a reweighting of the top quark $p_T$ in $t\bar{t}$ simulation. Displayed are number of muons (a), $p_T$ spectrum of muons (b), number of AK4 jets (c), $p_T$ distribution of all AK4 jets (d), number of b-tagged AK4 jets (e) and the spectrum of the missing transverse energy (f). }
 		\label{fig:PreSel_reweight}
 	\end{figure}	

\FloatBarrier %draw figures of previous section before the new one starts
\subsection{Measurement Phase Space}
\label{sec:FinalSel}
	The measurement phase space on reconstruction level is defined analogously to the particle level selection. Boosted topologies are selected by requiring the leading jet to surpass a cut on $p_T > 400\;\text{GeV}$. In addition the mass of the leading jet is expected to be higher then the second jet mass if all top quark decay products are reconstructed correctly. Thus, on top of the baseline selection presented above, following criteria are checked:
	\begin{itemize}
	\item only sum subjets with $p_T > 30\;\text{GeV}$ 
	\item $p_T^{\text{1st jet}} > 400\;\text{GeV}$ 
	\item $M^{\text{1st jet}} > M^{\text{2nd jet + lepton}}$
	\end{itemize}
	In this phase space, the selection criteria refer to XCone jets clustered with the '$2+6$' method.	In addition to the definition on particle level, only subjets with a $p_T$ larger then $30\;\text{GeV}$ are considered to form the final jet. This requirement is set so suppress subjets which do not contain any decay product of the top quark. Figure \ref{fig:MJet_raw1} shows the jet mass distribution after the called jet requirements. Similar as on particle level, XCone returns a peak at the expected bin of the top quark mass. Thus, the reconstruction with XCone jets works very well. As seen after the baseline selection, simulation exceeds the number of events in data. In Fig. \ref{fig:MJet_raw2}, $t\bar{t}$ simulation is scaled with a constant factor to match the total events in data and simulation. A good agreement between data and MC is visible. Of course, further procedure like unfolding will use the unscaled version as input. In addition another variant of jet clustering with XCone is presented in Fig. \ref{fig:MJet_raw3}. Here, the large XCone jet with radius $R=1.2$ is put into the soft drop algorithm. Albeit the grooming of soft drop, the '2+6' method returns a much sharper mass peak. While the turn on of the soft drop mass is comparable with '2+6', there are many event with a mass reconstructed too high.
 	\begin{figure}[tb]
 		\begin{subfigure}{.5\textwidth}
  		\centering
 		\includegraphics [width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_raw/M_jet1__lin.pdf}
 		\caption{}
 		\label{fig:MJet_raw1}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
 		\centering
		\begin{tikzpicture}
		 \node[anchor=south west,inner sep=0] (image) at (0,0)
		 {\includegraphics[width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_raw_SF/M_jet1__lin.pdf}};
		 \node[align=left,font=\tiny] at (2.2, 4.2) {$t\bar{t}$ scaled};
		\end{tikzpicture} 
 		\caption{}
 		\label{fig:MJet_raw2}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
 		\centering
		\begin{tikzpicture}
		 \node[anchor=south west,inner sep=0] (image) at (0,0)
		 {\includegraphics[width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_raw_SF/SoftdropMass_had_lin.pdf}};
		 \node[align=left,font=\tiny] at (2.2, 4.2) {$t\bar{t}$ scaled};
		\end{tikzpicture} 
 		\caption{}
 		\label{fig:MJet_raw3}
 		\end{subfigure} 		
 		\caption{Jet mass distribution of XCone jets after applying the measurement phase space requirements. Additional to the raw output (a) a distribution where $t\bar{t}$ simulation is scaled to data is presented (b). Histogram (c) shows the soft drop mass of the large XCone jet ($R=1.2$) in comparison. It shows that a grooming via subjet finding is much more effective than soft drop.}
 		\label{fig:MJet_raw}
 	\end{figure}
	
\FloatBarrier %draw figures of previous section before the new one starts	
\subsection{Jet Energy Corrections for XCone Jets} 
	The normal procedure in CMS analyses is to apply jet energy corrections (see section \ref{sec:jec}) to every jet collection used. Those jet energy corrections (JEC) have been derived by dedicated CMS groups and are different depending on the jet algorithm used to cluster jets. Since the XCone algorithm is not a standard jet finding procedure in CMS, there are no valid corrections available. Because the final jet measured in this a analysis is a combination of subjets, only the subjets are corrected. A XCone jet with applied jet energy corrections refers then to a jet put together from corrected subjets. The first attempt to correct XCone jets is to use the AK4 jet corrections since the jet shape should be very similar to XCone jets with $R=0.4$ as they were used in this analysis. Figure \ref{fig:MJet_jec} shows a comparison between jets with and without JEC applied. 
 	\begin{figure}[tb]
 		\begin{subfigure}{.5\textwidth}
 		\centering
		\begin{tikzpicture}
		 \node[anchor=south west,inner sep=0] (image) at (0,0)
		 {\includegraphics[width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_raw_SF/M_jet1__lin.pdf}};
		 \node[align=left,font=\tiny] at (2.2, 4.2) {$t\bar{t}$ scaled};
		\end{tikzpicture} 
 		\caption{}
 		\label{fig:MJet_jec1}
 		\end{subfigure}
 		\begin{subfigure}{.5\textwidth}
 		\centering
		\begin{tikzpicture}
		 \node[anchor=south west,inner sep=0] (image) at (0,0)
		 {\includegraphics[width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_jec_SF/M_jet1__lin.pdf}};
		 \node[align=left,font=\tiny] at (2.2, 4.2) {$t\bar{t}$ scaled};
		\end{tikzpicture} 
 		\caption{}
 		\label{fig:MJet_jec2}
 		\end{subfigure}
 		\caption{Jet mass distribution of XCone jets before (a) and after applying AK4 jet energy corrections (b). A shift in jet masses to higher values is visible.}
 		\label{fig:MJet_jec}
 	\end{figure}	
 	An obvious shift in jet mass is visible, resulting in a peak position above the top quark mass. Since the data-simulation agreement is well in both cases, different measures have to be defined to validate the jet energy correction. Now, an attempt is made to compare the subjets with a well known parameter in the theory. Therefore all three jet mass combinations $M_{ij}$ of two of the three subjets on the hadronic side are calculated. It is expected that the combination with the lowest jet mass should be sensitive to the $W$ mass which is very precisely measured to $80.4\;\text{GeV}$ \cite{Wmass}. As shown in Fig. \ref{fig:Wmass} the $W$ boson mass is reconstructed too high at values above $85\;\text{GeV}$. Therefore, applying jet energy correction from AK4 jets to XCone subjets is not valid.
  	\begin{figure}[tb]
  		\begin{subfigure}{.5\textwidth}
  		\centering
 		\begin{tikzpicture}
 		 \node[anchor=south west,inner sep=0] (image) at (0,0)
 		 {\includegraphics[width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_raw_subjets_SF/min_mass_Wjet_zoom_lin.pdf}};
 		 \node[align=left,font=\tiny] at (2.2, 4.2) {$t\bar{t}$ scaled};
 		\end{tikzpicture} 
  		\caption{}
  		\label{fig:Wmass1}
  		\end{subfigure}
  		\begin{subfigure}{.5\textwidth}
  		\centering
 		\begin{tikzpicture}
 		 \node[anchor=south west,inner sep=0] (image) at (0,0)
 		 {\includegraphics[width=\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_jec_subjets_SF/min_mass_Wjet_zoom_lin.pdf}};
 		 \node[align=left,font=\tiny] at (2.2, 4.2) {$t\bar{t}$ scaled};
 		\end{tikzpicture} 
  		\caption{}
  		\label{fig:Wmass2}
  		\end{subfigure}
  		\caption{Lowest jet mass combination $\min(M_{ij})$ without (a) and with (b) JEC applied. The position of the peak is expected to match the $W$ boson mass of $80.4\;\text{GeV}$. The shift after applying JEC shifts $\min(M_{ij})$ to higher values.} 
  		\label{fig:Wmass}
  	\end{figure}	
 	%todo Resolution (nur nach correction zeigen?)
	To still be able to correct XCone jets for response non linearities and pile-up effects, a correction factor on top of AK4 corrections is derived for XCone jets. For this, only events from $t\bar{t}$ simulation are used. Furthermore, only the subjets from the jet belonging to the hadronically decaying top quark are considered. Now a matching to generator jets is executed and the fraction $R=\frac{p_T^{\text{rec}}}{p_T^{\text{gen}}}$ calculated. This is done in different $p_T$ and $\eta$ regions. The mean $R$ is then filled in a two dimensional histogram representing the $p_T$-$\eta$-plane (see Fig. \ref{fig:Correction}). The bin boundaries are chosen to obtain enough statistics in each bin to suppress uncertainties (RMS and uncertainties in appendix Fig. \ref{fig:A_err} and \ref{fig:A_rms}). 
		\begin{figure}[tb]
			\centering
			\includegraphics [width=.7\textwidth]{../Plots/Correction/Mean_numbers}
			\caption{Mean values of $R=\frac{p_T^{\text{rec}}}{p_T^{\text{gen}}}$ in the $p_T$-$\eta$ plane.}
			\label{fig:Correction}
		\end{figure}	
	The correction factor applied to every XCone jet is now $f = \frac{1}{R}$. To get a smooth transition between the different regions, in every $\eta$ bin a polynomial function is fitted to get a factor $f(p_T)$. An example of the fit is shown in Fig. \ref{fig:Correction_fit} (all fit functions can be found in the appendix in Fig. \ref{fig:A_fits}). Now, every subjet from the first jet is corrected with a $p_T$ dependent function corresponding to its $\eta$ value.
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.5\textwidth]{../Plots/Correction/Fits_example}
		\caption{Example of fit function. The correction factors are derived from Fig. \ref{fig:Correction} and then fitted with a polynomial function of degree $2$.}
		\label{fig:Correction_fit}
	\end{figure}
	Now every subjet is corrected with a different $p_T$ dependent function according to its direction in $\eta$. It is to mention that because of the loose ends of the fit, the correction factor is set constant for $p_T > 425\;\text{GeV}$. To verify this correction the minimum jet mass from two subjets is again compared with the $W$ boson mass in Fig. \ref{fig:Wmass_cor}. It is shown that the peak position is in agreement with the measured $M_W = 80.4\;\text{GeV}$.
  	\begin{figure}[tb]
  		\centering
 		\begin{tikzpicture}
 		 \node[anchor=south west,inner sep=0] (image) at (0,0)
 		 {\includegraphics[width=.7\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_cor_subjets_SF/min_mass_Wjet_zoom_lin.pdf}};
 		 \node[align=left,font=\small] at (3.3, 6.5) {$t\bar{t}$ scaled};
 		\end{tikzpicture} 
   		\caption{Lowest jet mass combination $\min(M_{ij})$ after AK4 jet energy correction and the correction for XCone. The peak position is in agreement with the value of the $W$ boson mass of $80.4\;\text{GeV}$.} 
  		\label{fig:Wmass_cor}
  	\end{figure}	  
  	Furthermore, a matching via $\Delta R$ between jets on particle and reconstruction level is performed to calculate the relative $p_T$ deviation. A graph showing the mean and width (here calculated as RMS \footnote{root mean square}) of $\frac{p_T^\text{rec} - p_T^\text{gen}}{p_T^\text{gen}}$ in bins of $p_T^\text{rec}$ are presented in Fig. \ref{fig:Reso}. While the width of the distribution (Fig. \ref{fig:Reso2}) is not much influenced by the different jet energy correction stages, the mean spectrum shows a large improvement after additional correction. The raw XCone jets and the ones corrected with AK4 corrections show a dependence on $p_T$ where the corrected jets are flatly distributed. Additionally, the corrected jets show a constant mean around $0$ which indicates a well performing correction.
  	
  	\begin{figure}[tb]
  		\begin{subfigure}{.5\textwidth}
   		\centering
  		\includegraphics [width=\textwidth]{../Plots/Resolution_Subjets/pt_mean_rec_after}
  		\caption{}
  		\label{fig:Reso1}
  		\end{subfigure}
  		\begin{subfigure}{.5\textwidth}
   		\centering
  		\includegraphics [width=\textwidth]{../Plots/Resolution_Subjets/pt_rms_rec_after}
  		\caption{}
  		\label{fig:Reso2}
  		\end{subfigure}
  		\caption{Mean (a) and width (b) of the relative deviation in jet $p_T$ between particle and reconstruction level.}
  		\label{fig:Reso}
  	\end{figure}
  	
  	
\FloatBarrier %draw figures of previous section before the new one starts	
\subsection{Final Jet Mass Distribution}
	After the events ran through a baseline selection, a measurement phase space requirement and a new derived jet energy correction, the final jet mass distribution is presented in Fig. \ref{fig:MJet_final}. After scaling $t\bar{t}$ simulation with a constant factor, data and Monte Carlo prediction agree very well. Furthermore, the distribution peaks at the top quark mass and shows a good resolution. In addition the large amount of statistics is a promising point for the unfolding procedure.
		 
  	\begin{figure}[tb]
  		\centering
 		\begin{tikzpicture}
 		 \node[anchor=south west,inner sep=0] (image) at (0,0)
 		 {\includegraphics[width=.8\textwidth, trim=0 0 3cm 0, clip]{../Plots/PostSel/XCone_cor_SF/M_jet1__lin.pdf}};
 		 \node[align=left,font=\small] at (3.5, 7.0) {$t\bar{t}$ scaled};
 		\end{tikzpicture} 
  		\caption{Jet mass distribution of the corrected jets. This distribution will be used as input for further analysis steps.} 
  		\label{fig:MJet_final}
  	\end{figure}	

  	
\section{Unfolding}
\label{sec:unfolding}
	Most analyses at LHC measure distributions of appropriate variables and then compare the obtained results in data with event simulations. In this method the MC samples also include detector effects. What one measures in this case is the real distribution on particle level folded with an unknown detector function. Studying the difference in MC between particle level and reconstruction level, it is possible to calculate the probabilities that a measured value in a bin $y_i$ is originating from bin $x_i$ on particle level. A visualisation of this problem is drawn in Fig. \ref{fig:Unfolding}.	
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.6\textwidth]{../Images/Unfolding.png}
		\caption{Schematic view of an unfolding procedure. The goal is to unfold a measured distribution $\mathbf{y}$ to obtain a true distribution $\mathbf{x}$ without detector effects. Taken from \cite{tunfold}.}
		\label{fig:Unfolding}
	\end{figure}
	The matrix $\mathbf{A}$ describing migrations from bins in $\mathbf{x}$ to bins in $\mathbf{y}$ can be calculated using simulations where both distributions $\mathbf{x}$ and $\mathbf{y}$ are known. Then, the migration matrix can be used obtain an estimate for data on particle level. Following Eq. \ref{eq:unfold} denotes the basic problem one has to solve:
	\begin{equation}
	\tilde{y}_i = \sum_{j=1}^{m} A_{ij}\tilde{x}_j, 1 \leq i \leq n
	\label{eq:unfold}
	\end{equation}
	where $m$ and $n$ are the number of bins of the true and measured distributions, respectively. The tilde marks the statistical mean of $\mathbf{x}$ and $\mathbf{y}$. Here, one is interested in a distribution $x_j$ and not $\tilde{x}_j$ what makes this problem not trivial. If one only replaces $\tilde{y}_i \rightarrow y_i$ and $\tilde{x}_j \rightarrow x_j$ and solve for $x_j$ by inverting the matrix $\mathbf{A}$, statistical fluctuations of $\mathbf{y}$ would be amplified. Thus, fluctuations have to be damped with a regularisation.
	
\subsection{Regularised Unfolding with TUnfold}
	The TUnfold software package \cite{tunfold} provides a framework for regularised unfolding procedures in high energy physics. Equation \ref{eq:unfold_lagrange} shows the Lagrangian implemented in TUnfold that is minimised.
	\begin{eqnarray}
	\label{eq:unfold_lagrange}
	\mathcal{L}(x,\lambda) &=& \mathcal{L}_1 + \mathcal{L}_2 + \mathcal{L}_3 
	\\ \nonumber \text{with}
	\\ 
	\label{eq:unfold_lagrange1}
	\mathcal{L}_1 &=& (\mathbf{y} - \mathbf{Ax})^\intercal \mathbf{V_{yy}}^{-1} (\mathbf{y} - \mathbf{Ax}) 
	\\
	\label{eq:unfold_lagrange2}
	\mathcal{L}_2 &=& \tau^2 (\mathbf{x} - f_b \mathbf{x}_0)^\intercal (\mathbf{L}^\intercal \mathbf{L}) (\mathbf{x} - f_b \mathbf{x}_0) 
	\\
	\label{eq:unfold_lagrange3}
	\mathcal{L}_3 &=& \lambda (Y-\mathbf{e}^\intercal \mathbf{x}) \ \text{with} \ Y=\sum_{i} y_i \ \text{and} \ e_j = \sum_{i}A_{ij}
	\end{eqnarray}
	The first term $\mathcal{L}_1$ contains a standard least square minimisation where $\mathbf{V_{yy}}$ is the covariance matrix describing uncertainties. Secondly a regularisation with strength $\tau^2$ is used. A bias vector can be introduced using a factor $f_b$ and a vector $\mathbf{x}_0$ to suppress deviations of $\mathbf{x}$ from $f_b\mathbf{x}_0$. Additionally, three choices for the matrix $\mathbf{L}$ can be made to either regularise the absolute value, first or second derivative of $\mathbf{x}$. The final term $\mathcal{L}_3$ expresses an optional area constraint, checking differences in event counts between input and output.
	
\subsection{Migration Matrix}
	To perform an unfolding, a migration matrix has to be filled. A matrix entry $A_{ij}$ contains the number of events that is generated in bin $i$ and reconstructed in bin $j$. Thus, a projection on one dimension returns either the jet mass distribution on particle or reconstruction level. Only events from the $t\bar{t}$ samples are considered to construct the matrix. If an event passes the particle level selection (see section \ref{sec:GenSel}) and reconstruction level selection (see sections \ref{sec:PreSel} and \ref{sec:FinalSel}) it is filled in the according bin. To account for events that pass only one selection underflow bins are used, while jet masses above $400\;\text{GeV}$ are filled into overflow bins. Furthermore it has to be accounted for different weights because corrections like trigger and b-tagging scale factors as well as pile-up re-weighting are only applied on reconstruction level. Thus, the weight applied to an event is split into a generator level weight and a reconstruction level weight as shown in Eq. \ref{eq:weight}.	
	\begin{equation}
	\text{event weight} = \text{gen weight} \cdot \text{reco weight}
	\label{eq:weight}
	\end{equation}
	Because events without reconstruction level information only carry a generator weight, events are filled into underflow bins with a compensation weight according to Eq. \ref{eq:weight2} to match the total number of events.
	\begin{equation}
	\text{compensation weight} = \text{gen weight} \cdot (1 - \text{reco weight})
	\label{eq:weight2}
	\end{equation}		
	Figure \ref{fig:Migration} shows the migration matrix where every bin is scaled to the total event count in the whole column. Thus, an entry $A_{ij}$ gives the probability that an event generated in bin $i$ is reconstructed in bin $j$.
	
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.6\textwidth]{../Plots/Unfolding/Data/Migration_prob.pdf}
		\caption{Display of the migration matrix. Each bin is scaled to the total event count in a column.}
		\label{fig:Migration}
	\end{figure}
	 %todo Correlations beschreiben
	
\subsection{Closure Tests}
	%todo show projections?
	Two tests unfolding Monte Carlo samples are performed in this analysis. Firstly, a MC sample is unfolded with it self. Since the L-curve scan does not work when using statistically dependent samples, a $\tau$ value is set manually. Nevertheless, the output distribution of TUnfold is expected to exactly match the particle level distribution. The comparison presented in Fig \ref{fig:Unfolding_same} shows an exact accordance and proves a correct filling of the migration matrix. Another approach to furthermore test the L-curve scan is to split the MC sample into two statistically independent parts. Therefore $10\%$ are randomly selected and saved as pseudo data, while the other $90\%$ are used to construct the migration matrix.
	
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.6\textwidth]{../Plots/Unfolding/MC_Same/Unfold.pdf}
		\caption{Unfolding of a MC sample with itself.}
		\label{fig:Unfolding_same}
	\end{figure}

	\begin{figure}[tb]
		\centering
		\includegraphics [width=.6\textwidth]{../Plots/Unfolding/MC_Split/Unfold.pdf}
		\caption{Unfolding of a MC sample with a statistical independent one.}
		\label{fig:Unfolding_split}
	\end{figure}
	%todo plots diskutieren
	
\FloatBarrier %draw figures of previous section before the new one starts	
\subsection{Unfolding of Data}
	To perform an unfolding with data, background events have to be subtracted to obtain $t\bar{t}$ data only. For this procedure, backgrounds estimated from simulation are used. 
	\begin{figure}[tb]
		\centering
		\includegraphics [width=.6\textwidth]{../Plots/Unfolding/Data/Unfold.pdf}
		\caption{Unfolding of Data with the full MC sample.}
		\label{fig:Unfolding_data}
	\end{figure}
	
	%todo diskutiere plot
\section{Results}
\label{sec:results}
%todo nochmal phasenraum hinschreiben

